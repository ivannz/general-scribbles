{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCMC from scratch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a study of Markov Chain MOnte Carlo methods,\n",
    "and is inspired, in part, by these great papers: \n",
    "* A basic overview of sampling methods such as AR, MH and Gibbs\n",
    "  [Chib, Greenberg (1995)](http://web1.sph.emory.edu/users/hwu30/teaching/statcomp/papers/chibGreenbergMH.pdf)\n",
    ". Includes a hybrid MH-AR method (whrere the proposal is sampled from using AR)\n",
    "* A self contained introduction and study of Monte Carlo based on Hamiltonian dynamics\n",
    "  [Betancourt (2017)](https://arxiv.org/abs/1701.02434.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get inflated `rect` for better $2$-d plot aesthetics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rect(data, dim=0, r=5e-2, a=1e-3):\n",
    "    # deal with nans!\n",
    "    dims, brdc = [*range(data.dim())], data.dim()*[1]\n",
    "    dims.pop(dim)\n",
    "    brdc[dim] = -1\n",
    "    mask = (~torch.isfinite(data)).sum(dims) == 0\n",
    "    mask = mask.reshape(brdc[:dim+1])\n",
    "    \n",
    "    # get the enclosing rectangle ...\n",
    "    (uu, _), (ll, _) = data[mask].max(dim), data[mask].min(dim)\n",
    "\n",
    "    # ... center it, infalte, ...\n",
    "    cc = (uu + ll) / 2\n",
    "    uu, ll = uu - cc, ll - cc\n",
    "    uu = uu + abs(uu) * r + a\n",
    "    ll = ll - abs(ll) * r - a\n",
    "\n",
    "    # ... and translate back\n",
    "    return ll + cc, uu + cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a multi-modal density: we can evaluate it, know its structure,\n",
    "but not the normalizing constant.\n",
    "\n",
    "$$\n",
    "p(\\theta)\n",
    "    = \\tfrac1Z \\mathop{\\mathrm{exp}} \\bigl(\n",
    "        \\log f(\\theta)\n",
    "    \\bigr)\n",
    "    \\,.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a banana distribution:\n",
    "\n",
    "$$\n",
    "p(x)\n",
    "    \\propto p_{\\mathcal{N}(0, 1)} \\circ \\phi(x)\n",
    "    \\,, $$\n",
    "\n",
    "where $\\phi$ is the based on the\n",
    "[Banana](https://en.wikipedia.org/wiki/Rosenbrock_function)\n",
    "function and given by $\n",
    "\\phi\n",
    "\\colon \\mathbb{R}^2 \\to \\mathbb{R}^2\n",
    "\\colon (x, y) \\mapsto (a x, b (y-x^2))\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_banana_base(x, a=0.75, b=1.05):\n",
    "#     phi = torch.stack([a - x[..., 0], b * (x[..., 1] - x[..., 0]**2)], dim=-1)  # a=1.75, b=5\n",
    "    phi = torch.stack([a * (x[..., 0] - x[..., 1]**2), b * (x[..., 1] - x[..., 0]**2)], dim=-1)\n",
    "    return -0.5 * torch.norm(phi, p=2, keepdim=False, dim=-1)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_density(x):\n",
    "    mu = map(torch.tensor, [(2., 2.), (-2., -2.)])\n",
    "    a, b, s = [+0.75, -0.75], [+3.05, -1.05], [+1, -1]\n",
    "\n",
    "    compo = map(lambda m, a, b, s: log_banana_base(s*(x - m.to(x)), a, b), mu, a, b, s)\n",
    "    stacked = torch.stack([*compo], dim=0)\n",
    "\n",
    "    return torch.logsumexp(stacked, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_funnel(x, a=5e-1, b=1.):\n",
    "#     return -0.5 * (a * x[..., 1]**2 + torch.exp(- b * x[..., 1]) * x[..., 0]**2)\n",
    "    return -0.5 * (a * (torch.exp(- b * x[..., 0]) - x[..., 1])**2\n",
    "                   + torch.exp(- b * x[..., 1]) * x[..., 0]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_density = log_funnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def log_density(x):\n",
    "#     return -0.5 * torch.norm(x, p=2, keepdim=False, dim=-1)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And a plot of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = torch.meshgrid(2*[torch.linspace(-5, +16, 101)])\n",
    "marg = torch.stack(mesh, dim=-1).flatten(0, -2)\n",
    "\n",
    "z = torch.exp(log_density(marg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, xlabel=r\"$\\theta_1$\", ylabel=r\"$\\theta_2$\",\n",
    "                    title=\"2x'blob' density\")\n",
    "\n",
    "ax.contourf(*mesh, z.reshape_as(mesh[0]), levels=51, cmap=plt.cm.terrain)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the gradient field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = marg.clone().requires_grad_(True)\n",
    "log_density(theta).mean().backward()\n",
    "\n",
    "dz = theta.grad.reshape(*mesh[0].shape, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, xlabel=r\"$\\theta_1$\", ylabel=r\"$\\theta_2$\",\n",
    "                    title=\"2x'blob' density\")\n",
    "\n",
    "ax.contourf(*mesh, z.reshape_as(mesh[0]), levels=51, cmap=plt.cm.terrain)\n",
    "\n",
    "if True:\n",
    "    ax.quiver(*mesh, dz[..., 0], dz[..., 1], pivot='mid',\n",
    "              color=\"fuchsia\", scale_units='xy', angles='uv', scale=.5, alpha=0.5)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create some samplers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Proposal:\n",
    "    def sample(self, n_samples=1, *, at=None):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def log_prob(self, x, *, at=None):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sample_chain(sampler, n_steps=501, n_chains=15):\n",
    "    chain = [torch.randn(n_chains, 2) * 15]\n",
    "#     chain = [torch.randn(1, 2).repeat(n_chains, 1) * 15]\n",
    "    for _ in tqdm.trange(n_steps):\n",
    "        chain.append(sampler.sample(1, at=chain[-1]))\n",
    "\n",
    "    return torch.stack(chain, dim=-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A path plotter using quiver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_path(path, ax=None, **kwargs):\n",
    "    ax = plt.gca() if ax is None else ax\n",
    "\n",
    "    uv, xy = path[1:] - path[:-1], path[:-1]\n",
    "\n",
    "    size = np.linalg.norm(uv, axis=-1, keepdims=False)\n",
    "    stuck = path[1:][size == 0]\n",
    "\n",
    "    ax.scatter(stuck[:, 0], stuck[:, 1], c=\"k\", alpha=0.1)\n",
    "\n",
    "    return ax.quiver(xy[:, 0], xy[:, 1], uv[:, 0], uv[:, 1],\n",
    "                     scale_units='xy', angles='xy', scale=1.,\n",
    "                     **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the Markov Chain paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_chains(paths, log_density):\n",
    "    fig = plt.figure(figsize=(16, 16))\n",
    "    fig.patch.set_alpha(1.0)\n",
    "\n",
    "    # get the mesh\n",
    "    ll, ur = get_rect(paths.flatten(0, -2))\n",
    "    mesh = torch.meshgrid(*map(torch.linspace, ll, ur, [201, 201]))\n",
    "    marg = torch.stack(mesh, dim=-1).flatten(0, -2)\n",
    "    z = torch.exp(log_density(marg))\n",
    "\n",
    "    ax = fig.add_subplot(111, xlabel=r\"$\\theta_1$\", ylabel=r\"$\\theta_2$\")\n",
    "\n",
    "    ax.contourf(*mesh, z.reshape_as(mesh[0]), levels=21,\n",
    "               cmap=plt.cm.terrain, alpha=0.05, zorder=10)\n",
    "\n",
    "    colours = plt.cm.Accent(np.linspace(0, 1, num=len(paths)))\n",
    "    for i, col in enumerate(colours):\n",
    "        pts = paths[i].numpy()\n",
    "        plot_path(pts, color=col, alpha=.5)\n",
    "    #     ax.scatter(pts[:, 0], pts[:, 1], color=col, s=10, alpha=0.05)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a measurable space $(\\Omega, \\mathcal{F}, \\mu)$.\n",
    "The Markov Chain sampler needs:\n",
    "* *(proposal)* the transition `kernel`\n",
    "$P \\colon \\Omega \\times \\mathcal{F} \\to [0, 1]$\n",
    "\n",
    "In MC-MC we typically consider kernels over Lebsegue carrier measures\n",
    "$\\mu = d{x}$ and defined by\n",
    "\n",
    "$$\n",
    "P(x, d\\omega)\n",
    "    = q(\\omega \\vert x) \\mu(d\\omega) + r(x) \\delta_x(d\\omega)\n",
    "    \\,, $$\n",
    "\n",
    "where $Q(\\bullet \\vert x) = q(\\cdot \\vert x) \\mu(d\\omega)$ is a nonnegative measure\n",
    "with $Q(\\Omega\\vert x) \\leq 1$ and  $q(x \\vert x) = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this notation mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, $\\delta_x(\\cdot)$ defines a probability measure on the\n",
    "measurable space $(\\Omega, \\mathcal{F})$ according to\n",
    "\n",
    "$$\n",
    "\\delta_x\n",
    "\\colon \\mathcal{F} \\to [0, 1]\n",
    "\\colon A \\mapsto 1_A(x)\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notation is a shorthand for (like in SDE)\n",
    "$$\n",
    "P(x, dy) = q(y \\vert x) dy + r(x) \\delta_x(dy)\n",
    "    \\Leftrightarrow\n",
    "    P(x, A)\n",
    "        = \\int_A q(y \\vert x) dy + r(x) \\delta_x(dy)\n",
    "        = Q(A \\vert x) + r(x) 1_A(x)\n",
    "    \\,, $$\n",
    "\n",
    "This implies that for $P(x, \\cdot)$ to be a probability measure\n",
    "we need $r(x) = 1 - Q(\\Omega \\vert x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Did i really need this proof? NO!\n",
    "\n",
    "$\\delta_x(\\emptyset) = 1_\\emptyset(x) = 0$, and\n",
    "$$\n",
    "\\delta_x\\bigl(\\biguplus_{n\\geq 1} A_n\\bigr)\n",
    "    = 1_{\\uplus_{n\\geq 1} A_n}(x)\n",
    "    = \\begin{cases}\n",
    "    1 & \\exists{n\\geq1}\\, x \\in A_n\\\\\n",
    "    0 & \n",
    "    \\end{cases}\n",
    "    = \\sum_{n\\geq 1} 1_{A_n}(x)\n",
    "    = \\sum_{n\\geq 1} \\delta_x(A_n)\n",
    "    \\,. $$\n",
    "\n",
    "Via the MCT this implies that $\\int f \\delta_x(d\\omega) = f(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Target(Proposal):\n",
    "    def __init__(self, fn):\n",
    "        self.fn = fn\n",
    "\n",
    "    def log_prob(self, x, *, at=None):\n",
    "        return self.fn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndependentProposal(Proposal):\n",
    "    def __init__(self, distribution):\n",
    "        self.distribution = distribution\n",
    "    \n",
    "    def log_prob(self, x, *, at=None):\n",
    "        return self.distribution.log_prob(x)\n",
    "\n",
    "    def sample(self, n_samples=1, *, at):\n",
    "        *head, n_features = at.shape\n",
    "        return self.distribution.sample((*head, n_samples)).squeeze(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWalkProposal(Proposal):\n",
    "    def __init__(self, distribution):\n",
    "        self.distribution = distribution\n",
    "\n",
    "    def log_prob(self, x, *, at):\n",
    "        return self.distribution.log_prob(x - at)\n",
    "\n",
    "    def sample(self, n_samples=1, *, at):\n",
    "        *head, n_features = at.shape\n",
    "\n",
    "        step = self.distribution.sample((*head, n_samples))\n",
    "        return (at.unsqueeze(-2) + step).squeeze(-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate gradients of a scalar function in bulk, observe the following:\n",
    "$$\n",
    "(\\nabla_\\theta f(\\theta_i))_{i}\n",
    "    \\colon (\\theta_i)_{i} \\mapsto\n",
    "        \\bigl(\n",
    "            \\tfrac{\\partial}{\\partial \\theta_j}\n",
    "                \\sum_i f(\\theta_i)\n",
    "        \\bigr)_{ji} \\mathbf{1}\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_grad(x, f, **kwargs):\n",
    "    theta = x.clone().requires_grad_(True)\n",
    "    f(theta, **kwargs).sum().backward()\n",
    "    return theta.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def f(x, q):\n",
    "    return - log_density(x) + 0.5 * torch.norm(q, p=2, dim=-1)**2\n",
    "\n",
    "from torch.autograd import grad\n",
    "\n",
    "x = torch.randn(10, 2).requires_grad_(True)\n",
    "q = torch.randn_like(x).requires_grad_(True)\n",
    "\n",
    "par = x, q\n",
    "dx, dq = grad(f(*par).sum(), par, create_graph=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A handy function for clipping a tenspr's norm:\n",
    "$$ \n",
    "    x \\mapsto x \\min\\bigl\\{\\tfrac{C}{\\| x \\|_p}, 1 \\bigr\\}\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_norm(x, max_norm, p=2, dim=-1, inplace=True):\n",
    "    mul = torch.Tensor.mul_ if inplace else torch.Tensor.mul\n",
    "\n",
    "    # an ell-p norm grad clipping step\n",
    "    norm = torch.norm(x, p=p, dim=dim, keepdim=True)\n",
    "    x = mul(x, torch.clamp(max_norm / norm, max=1))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langevin proposal\n",
    "\n",
    "The SDE\n",
    "\n",
    "$$\n",
    "dX_t\n",
    "    = \\mu_t(X_t) dt\n",
    "    + \\sigma_t(X_t) dW_t\n",
    "    \\,, $$\n",
    "\n",
    "can be numerically approximated using Euler-Maruyama method: for $\\delta > 0$\n",
    "\n",
    "$$\n",
    "X_{t+\\delta} - X_t\n",
    "    = \\mu_t(X_t) \\delta\n",
    "    + \\sigma_t(X_t) \\sqrt{\\delta} \\xi_t\n",
    "    \\,, $$\n",
    "\n",
    "where $\\xi_t \\sim \\mathcal{N}(0, I)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider Langevin's Îto diffusion:\n",
    "\n",
    "$$\n",
    "d\\theta_t\n",
    "    = \\nabla_\\theta \\log \\pi(\\theta_t) dt\n",
    "    + \\sqrt{2} dW_t\n",
    "    \\,. $$\n",
    "\n",
    "The Euler-Maruyama step with $\\delta > 0$ yields the following\n",
    "finite-difference approximation\n",
    "\n",
    "$$\n",
    "\\theta_{t + \\delta}\n",
    "    = \\theta_t\n",
    "    + \\delta \\nabla_\\theta \\log \\pi(\\theta_t)\n",
    "    + \\sqrt{2 \\delta} \\xi_t\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the proposal is \n",
    "\n",
    "$$\n",
    "q(\\theta \\vert x)\n",
    "    = \\mathcal{N}\\bigl(\n",
    "        \\theta \\,\\big\\vert\\,\n",
    "        x + \\delta \\nabla_\\theta \\log \\pi(\\theta) \\vert_{\\theta=x},\n",
    "        2 \\delta I\n",
    "    \\bigr)\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that, if $x = \\mu+ \\sigma \\xi$ and $\\xi \\sim p_\\xi$, then \n",
    "$$\n",
    "p_x(x)\n",
    "    = \\tfrac1\\sigma p_\\xi(\\tfrac{x - \\mu}\\sigma)\n",
    "    \\,, \\text{ or }\\,\n",
    "    p_\\xi(\\xi)\n",
    "        = \\sigma p_x(\\mu + \\sigma \\xi)\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class LangevinProposal(Proposal):  # , RandomWalkProposal):\n",
    "    def __init__(self, proposal, target, delta=1e-2, clip_grad=0):\n",
    "        self.target, self.delta = target, delta\n",
    "        self.proposal, self.clip_grad = proposal, clip_grad\n",
    "\n",
    "    def log_prob(self, x, *, at):\n",
    "        z = (x - self.mu(at=at)) / math.sqrt(2 * self.delta)\n",
    "\n",
    "        return self.proposal.log_prob(z) - 0.5 * math.log(2 * self.delta)\n",
    "    \n",
    "    def mu(self, *, at):\n",
    "        grad = batch_grad(at, self.target.log_prob)\n",
    "\n",
    "        # an ell-2 norm grad clipping step\n",
    "        if self.clip_grad > 0:\n",
    "            grad = clip_norm(grad, self.clip_grad, p=2, dim=-1)\n",
    "\n",
    "        return at + grad * self.delta\n",
    "\n",
    "    def sample(self, n_samples=1, *, at):\n",
    "        *head, n_features = at.shape\n",
    "\n",
    "        step = math.sqrt(2 * self.delta) * self.proposal.sample((*head, n_samples))\n",
    "        return (self.mu(at=at).unsqueeze(-2) + step).squeeze(-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x \\in \\Omega^{b_1 \\times \\ldots \\times b_p}$ for $\\Omega \\subseteq \\mathbb{R}$\n",
    "and any transition kernel must "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MH kernel is given by the density:\n",
    "$$\n",
    "P(x, dy)\n",
    "    = p(x, y) dy + r(x) \\delta_x(dy)\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metropolis-Hastings Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some transition density (or pmf) $p(y \\vert x)$ the transition kernel\n",
    "$$\n",
    "P(x, dy)\n",
    "%     = p(dy \\vert x) + r(x) \\delta_x(dy)\n",
    "    = p(y \\vert x) dy + r(x) \\delta_x(dy)\n",
    "    \\,, $$\n",
    "with $r(x) = 1 - \\int_\\Omega p(dy \\vert x) \\leq 1$ has $\\pi$ as the stationary\n",
    "distribution if $p$ complies with the detailed (micro-) balance condition:\n",
    "$\n",
    "\\pi(dx) p(dy \\vert x) = \\pi(dy) p(dx \\vert y)\n",
    "$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we have\n",
    "$$\n",
    "\\begin{align}\n",
    "\\int_\\Omega \\pi(dx) P(x, B)\n",
    "    &= \\int_\\Omega \\pi(dx) \\int_B P(x, dy)\n",
    "    = \\int_\\Omega \\int_B p(dy \\vert x) \\pi(dx)\n",
    "      + \\int_\\Omega \\int_B r(x) \\delta_x(dy) \\pi(dx)\n",
    "    \\\\\n",
    "    &= \\int^x_\\Omega \\int^y_B p(dy \\vert x) \\pi(dx)\n",
    "      + \\int_\\Omega r(x) 1_B(x) \\pi(dx)\n",
    "    = \\int^y_B \\int^x_\\Omega p(dx \\vert y) \\pi(dy) + \\int_B r(x) \\pi(dx)\n",
    "    \\\\\n",
    "    &= \\int_B (1 - r(y)) \\pi(dy) + \\int_B r(x) \\pi(dx)\n",
    "    = \\pi(B)\n",
    "    \\,,\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus for a chosen proposal density $q(dy \\vert x)$ we need to find\n",
    "a transition density $p(dy \\vert x)$, that satisfies the balance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(heuristic)** Let's use importance sampling (analogue of): introduce a rv that\n",
    "controls the transitions and adjusts the resulting `density` so that is has the\n",
    "needed mass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider $\n",
    "p(y\\vert x)\n",
    "    = q(y\\vert x) \\alpha(y \\vert x)\n",
    "$, where $\\alpha$ enforces `reversibility`:\n",
    "$$\n",
    "\\pi(dx) q(dy\\vert x) \\alpha(y \\vert x)\n",
    "    = \\pi(dy) q(dx\\vert y) \\alpha(x \\vert y)\n",
    "    \\,. $$\n",
    "\n",
    "Assuming $\\pi(dx) = \\pi(x) dx$ and $q(dy \\vert x) = q(y\\vert x) dy$ we\n",
    "may observe the following:\n",
    "* If $\\pi(x) q(y\\vert x) > \\pi(y) q(x\\vert y)$ then $\n",
    "\\alpha(y \\vert x)\n",
    "    = \\tfrac{\\pi(y) q(x\\vert y)}{\\pi(x) q(y\\vert x)}\n",
    "$ and $\\alpha(x \\vert y) = 1$\n",
    "\n",
    "* If $\\pi(x) q(y\\vert x) < \\pi(y) q(x\\vert y)$ then $\n",
    "\\alpha(x \\vert y)\n",
    "    = \\tfrac{\\pi(x) q(y\\vert x)}{\\pi(y) q(x\\vert y)}\n",
    "$ and $\\alpha(y \\vert x) = 1$\n",
    "\n",
    "Thus the sought $\\alpha$ is\n",
    "$$\n",
    "\\alpha(y\\vert x)\n",
    "    = \\min\\Bigl\\{\n",
    "        1, \\frac{\n",
    "            \\overbrace{\n",
    "                \\pi(y) q(x\\vert y)\n",
    "            }^{\n",
    "                y \\to x\n",
    "            }\n",
    "        }{\n",
    "            \\underbrace{\\pi(x) q(y\\vert x)}_{\n",
    "                x \\to y\n",
    "            }\n",
    "        }\n",
    "    \\Bigr\\}\n",
    "    \\,. $$\n",
    "\n",
    "It is called the *probability of move*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus the basic step of MH MC sampler is: given $x_t$ do\n",
    "1. sample $y \\sim q(y \\vert x_t)$\n",
    "2. independently draw $u \\sim \\mathrm{U}[0, 1]$ and\n",
    "    * set $x_{t+1} = y$ if $u \\leq \\alpha(y\\vert x_t)$\n",
    "    * put $x_{t+1} = x_t$ otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetropolisHastingsProposal(Proposal):\n",
    "    def __init__(self, proposal, target):\n",
    "        self.target, self.proposal = target, proposal\n",
    "\n",
    "    def sample(self, n_samples=1, *, at):\n",
    "        *head, n_features = at.shape\n",
    "        head = [1] if not head else head\n",
    "\n",
    "        p, q = self.target, self.proposal\n",
    "\n",
    "        assert n_samples == 1\n",
    "        prop, curr = q.sample(n_samples, at=at), at\n",
    "        # curr = curr.unsqueeze(-2)  # DON'T : dimension growth! but gives branching paths!\n",
    "\n",
    "        # \\log \\pi(prop) q(curr \\vert prop)\n",
    "        log_alpha  = q.log_prob(curr, at=prop) + p.log_prob(prop)\n",
    "\n",
    "        # - \\log \\pi(curr) q(prop \\vert curr)\n",
    "        log_alpha -= q.log_prob(prop, at=curr) + p.log_prob(curr)\n",
    "\n",
    "        alpha = torch.exp(torch.clamp(log_alpha, max=0))\n",
    "\n",
    "        accept = torch.rand_like(log_alpha) <= alpha\n",
    "\n",
    "        # print(accept.float().mean(), alpha)\n",
    "        self.alpha_, self.log_alpha_ = alpha, log_alpha\n",
    "\n",
    "        return torch.where(accept.unsqueeze(-1), prop, curr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [Betancourt (2017) p.11](https://arxiv.org/abs/1701.02434)\n",
    "* **(first phase)** MC travels towards the typical set. MC-based\n",
    "estimators have strong bias (*burn-in*)\n",
    "\n",
    "* **(second phase)** MC `persists through the first sojourn across the typical set`.\n",
    "Accuracy of estimators improves as the bias from burn-in dampens\n",
    "\n",
    "* **(third phase)** MC continues and gradually refines its exploration\n",
    "of the typical set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a random walk transition kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  torch.distributions import MultivariateNormal\n",
    "\n",
    "proposal = RandomWalkProposal(MultivariateNormal(torch.zeros(2), torch.eye(2)))\n",
    "rwmh = MetropolisHastingsProposal(proposal, Target(log_density))\n",
    "\n",
    "plot_chains(sample_chain(rwmh, n_chains=15), log_density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss = MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
    "# ldp = LangevinProposal(gauss, Target(log_density), delta=1e-1, clip_grad=1e1)\n",
    "ldp = LangevinProposal(gauss, Target(log_density), delta=1e-2, clip_grad=5e2)\n",
    "ldmh = MetropolisHastingsProposal(ldp, Target(log_density))\n",
    "\n",
    "plot_chains(sample_chain(ldmh, n_steps=501, n_chains=15), log_density)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [Betancourt (2017) pp. 16-19](https://arxiv.org/abs/1701.02434)\n",
    "\n",
    "Although MH with Random Walk proposal (aka RandomWalk Metropolis, RWMH) is simple\n",
    "and intuitive clear, it drammatically suffers from the curse of dimensionality\n",
    "and the complexity of the target distribution.\n",
    "\n",
    "> ... the volume exterior to the typical set overwhelms the interior volume\n",
    "and almost every RWMH chain gets stuck outside of the typical set towards the\n",
    "tails, due to low acceptance rate, induced by negligible densities. ... In the\n",
    "worst case RWMH won't even complete a single sojourn through the typical set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea behind Hamiltonian MC is to use first order information,\n",
    "$\\nabla_\\theta \\log \\pi(\\theta)$, about the target distribution $\\pi(\\theta)$\n",
    "to make informed moves towards the typical set. However, by itself\n",
    "the gradient pulls towrads a mode of $\\pi(\\theta)$ and would make\n",
    "the chain collapse in it, which is not the typical set (what is it then?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in HMC we consider $\\pi(\\theta, m) = \\pi(\\theta) p(m \\vert \\theta)$\n",
    "where we have introduced auxiliary random varaible, momentum $m$. This\n",
    "`lifts the target distribution onto a joint probability distribution on\n",
    "pahse space` If the momentum is marginalized, then the original target\n",
    "density is recovred, which means that during sampling we can simply discard\n",
    "$m$ when requesting a sampel of $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider $\\pi(\\theta, m) = \\exp\\bigl\\{ - H(\\theta, m) \\bigr\\}$. Then for a\n",
    "trajectory $t\\mapsto (\\theta_t, m_t)$ so stay on the level set of $H$\n",
    "we must have $\\tfrac{d}{d t} H(\\theta_t, m_t) = 0$, i.e.\n",
    "\n",
    "$$\n",
    "dH = \\nabla_\\theta^\\top H(\\theta_t, m_t) \\dot{\\theta}_t dt\n",
    "    + \\nabla_m^\\top H(\\theta_t, m_t) \\dot{m}_t dt\n",
    "    = 0\n",
    "    \\,, $$\n",
    "\n",
    "which is satisfied when\n",
    "$$\n",
    "\\dot{\\theta}_t = \\nabla_m H(\\theta_t, m_t)\n",
    "    \\,,\\,\n",
    "    \\dot{m}_t = \\nabla_\\theta H(\\theta_t, m_t)\n",
    "    \\,. $$\n",
    "\n",
    "Typically the Hamiltonian is decomposed as\n",
    "\n",
    "$$\n",
    "H(\\theta, m)\n",
    "    = - \\log \\pi(\\theta) p(m \\vert \\theta)\n",
    "    = \\underbrace{- \\log \\pi(\\theta)}_{\\text{potential}}\n",
    "    + \\bigl(\n",
    "        \\underbrace{- \\log p(m \\vert \\theta)}_{\\text{kinetic}}\n",
    "    \\bigr)\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [Betancourt (2017) pp. 27](https://arxiv.org/abs/1701.02434)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choice of the kinetic energy term is what determines the interaction if the Chain with the target.\n",
    "Herein lies the scope of HMC design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The randomness in HMC scheme comes from the randomness of the `momentun lift`,\n",
    "whereas the traversal of the level of $H$ is deterministic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the HMC trajectory journies along the level set in the phase-space,\n",
    "it is natural to factorize the canonical distribution $\\pi(\\theta, m)$,\n",
    "byt foliating into concentric level sets:\n",
    "\n",
    "$$\n",
    "\\pi(\\theta, m)\n",
    "    = \\pi(x_E \\vert H(x_E) = E)\n",
    "    \\, \\pi(H(x_E) = E)\n",
    "    \\,. $$\n",
    "\n",
    "Lifts determine jumps beteween the energy levels, while each tajectory explores\n",
    "the corresponding level set $\\{H(\\theta, m) = E\\}$. Thus we get two phases\n",
    "\n",
    "* deterministic traversal of energy level sets (how long we integrate)\n",
    "* stochastic exploration between level sets (how quickly jumps `diffuse accross energies typical to the energy marginal distribution`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following kinetic energy is called Euclidean-Gaussian if $G(\\theta) = \\Sigma$,\n",
    "and Riemannian-Gaussian if $G(\\theta) = $.\n",
    "\n",
    "* we can optimize $\\Sigma$ using the extendend burn-in pahse\n",
    "[Betancourt (2017) pp. 31](https://arxiv.org/abs/1701.02434)\n",
    "\n",
    "* if $G(\\theta)$ resembles the Hessian of the target, i.e. its Fisher info-matrix,\n",
    "then the energy level exploration would be uniform and efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the integration time: if we integrate for a short period of time,\n",
    "we risk having insufficient diversity on the samples as they would tend to\n",
    "clump together. On the other hand, long integration times can degrade exploration\n",
    "in case when the level sets are `topologically` compact (is there any other\n",
    "notion of compactness?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic Ergodicity for orbits $\\phi = \\{(\\theta_t, m_t)\\colon t \\geq 0\\}$ states\n",
    "that a uniform temporal sample form a trajectory resemples a uniform spatial sample\n",
    "from $\\phi$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplectic integrators [Betancourt (2017) pp. 36](https://arxiv.org/abs/1701.02434)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try to integrate something"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Cauchy problem for ODE $$\n",
    "\\dot{x}\n",
    "    = A x\\,, x(0) = x_0\n",
    "\\,. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euler(x, f, eps=1e-3):\n",
    "    return x + f(x) * eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = lambda x: np.dot(x, np.array([\n",
    "    [-1., +2.],\n",
    "    [-10., -1.],\n",
    "]))\n",
    "\n",
    "grad = lambda x: np.dot(x, np.array([\n",
    "    [0, +1.],\n",
    "    [-1., 0],\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [np.random.randn(5, 2)]\n",
    "for _ in range(100):\n",
    "    paths.append(euler(paths[-1], grad, eps=1e-1))\n",
    "\n",
    "paths = np.stack(paths, axis=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "colours = plt.cm.Reds(np.linspace(0.5, 1, num=len(paths)))\n",
    "for i, col in enumerate(colours):\n",
    "    plot_path(paths[i], color=col, alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_mesh = np.meshgrid(\n",
    "    np.linspace(-5, +5, num=101),\n",
    "    np.linspace(-5, +5, num=101),\n",
    ")\n",
    "np_marg = np.stack(np_mesh, axis=-1).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uv = grad(np_marg).reshape(*np_mesh[0].shape, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, xlabel=r\"$\\theta_1$\", ylabel=r\"$\\theta_2$\",\n",
    "                    title=\"2x'blob' density\")\n",
    "\n",
    "ax.quiver(*np_mesh, uv[..., 0], uv[..., 1], pivot='mid',\n",
    "          color=\"fuchsia\", scale=2000., alpha=0.5)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Hamiltonian MonteCarlo we need a hamiltonian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets introduce an auxiliary variable $q \\approx \\dot{\\theta}$ with\n",
    "$p(q\\vert \\theta) = \\mathcal{N}(q \\vert 0, G(\\theta))$. Then the\n",
    "joint density of $(\\theta, q)$\n",
    "\n",
    "$$\n",
    "p(\\theta, q)\n",
    "    = p(\\theta) p(q\\vert \\theta)\n",
    "    \\propto \\exp{(- H(\\theta, q))}\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "H(\\theta, q)\n",
    "    = - \\ell(\\theta)\n",
    "    + \\tfrac12\\log\\det 2 \\pi G(\\theta)\n",
    "    + \\tfrac12 q^\\top G(\\theta)^{-1} q\n",
    "    \\,, $$\n",
    "with $\\ell(\\theta) = \\log p(\\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hamiltonian dynamics in the case of $q$ behaving like a momentum\n",
    "of $\\theta$ is\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\dot{\\theta}\n",
    "        =& \\partial_q H(\\theta, q)\n",
    "        \\,, \\\\\n",
    "   - \\dot{q}\n",
    "        =& \\partial_\\theta H(\\theta, q)\n",
    "        \\,,\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the derivative of $\\log-\\det$ is\n",
    "\n",
    "$$\n",
    "\\partial_\\theta \\log \\det G(\\theta)\n",
    "    = - \\partial_\\theta \\log \\det G(\\theta)^{-1}\n",
    "    = - \\mathrm{tr}\n",
    "        \\tfrac1{\\det G(\\theta)^{-1}} (\\det G(\\theta)^{-1})\n",
    "            G(\\theta)^\\top \\partial_\\theta G(\\theta)^{-1}\n",
    "    = - \\mathrm{tr} G(\\theta) \\partial_\\theta G(\\theta)^{-1}\n",
    "    \\,, $$\n",
    "\n",
    "and the second term is\n",
    "\n",
    "$$\n",
    "\\partial_\\theta \\tfrac12 q^\\top G(\\theta)^{-1} q\n",
    "    = \\tfrac12 \\mathrm{tr} q q^\\top \\partial_\\theta G(\\theta)^{-1}\n",
    "    \\,. $$\n",
    "\n",
    "And $\n",
    "\\partial_\\theta G(\\theta)^{-1}\n",
    "    = - G(\\theta)^{-1}\n",
    "        \\bigl( \\partial_\\theta G(\\theta) \\bigr)\n",
    "    G(\\theta)^{-1}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dynamics is thus\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\dot{\\theta}\n",
    "        =& G(\\theta)^{-1} q\n",
    "        \\,, \\\\\n",
    "    - \\dot{q}\n",
    "%         =& - \\partial_\\theta \\ell(\\theta)\n",
    "%            + \\tfrac12 \\mathrm{tr} \\bigl(\n",
    "%                q q^\\top - G(\\theta)\n",
    "%            \\bigr) \\partial_\\theta G(\\theta)^{-1}\n",
    "        =& - \\partial_\\theta \\ell(\\theta)\n",
    "           - \\tfrac12 \\mathrm{tr} G(\\theta)^{-1} \\bigl(\n",
    "               q q^\\top - G(\\theta)\n",
    "           \\bigr) G(\\theta)^{-1}\n",
    "           \\partial_\\theta G(\\theta)\n",
    "        \\,,\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $G(\\theta) = \\Sigma$ we have\n",
    "\n",
    "$$\n",
    "\\dot{\\theta} = \\Sigma^{-1} q\n",
    "    \\,, \\dot{q} = \\partial_\\theta \\ell(\\theta)\n",
    "    \\,, $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\ddot{x} = F(x)\n",
    "    \\Leftrightarrow\n",
    "    \\dot{x} = v\n",
    "    \\,, \\dot{v} = F(x)\n",
    "\\,. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{pmatrix}\n",
    "    \\dot{q} \\\\ \\dot{p}\n",
    "\\end{pmatrix}\n",
    "    = \\begin{pmatrix}\n",
    "        0 & \\partial_p \\\\\n",
    "        - \\partial_q & 0\n",
    "    \\end{pmatrix}\n",
    "    H(q, p)\n",
    "    \\,, $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Euclidean-Gaussian kinetic energy we have\n",
    "\n",
    "$$\n",
    "H(\\theta, q)\n",
    "    = - \\log p(\\theta)\n",
    "    + \\tfrac12\\log\\det 2 \\pi \\Sigma\n",
    "    + \\tfrac12 q^\\top \\Sigma^{-1} q\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamiltonian(x, q):\n",
    "    return - log_density(x) + 0.5 * torch.norm(q, p=2, dim=-1)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence the dynamics obeys\n",
    "\n",
    "$$\n",
    "\\dot{\\theta} = \\Sigma^{-1} q\n",
    "    \\,,\\, \\dot{q} = - \\nabla_\\theta H(\\theta, q) = \\nabla_\\theta \\log p(\\theta)\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For $\\tau = s t$, $s = \\pm 1$ we have:\n",
    "\n",
    "$$\n",
    "\\frac{d x}{d \\tau}\n",
    "    = \\frac{d x}{d t} \\frac{d t}{d \\tau}\n",
    "    % = \\frac{d x}{d t} \\frac1s\n",
    "    = s \\frac{d x}{d t}\n",
    "    \\,, $$\n",
    "\n",
    "whence the dynamics becomes\n",
    "\n",
    "$$\n",
    "\\dot{\\theta} = \\Sigma^{-1} s q\n",
    "    \\,,\\, \\dot{q} = s \\nabla_\\theta \\log p(\\theta)\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_(H, x, q, *, epsilon=1e-3, M=None, inplace=False, clip_grad=0):\n",
    "    # applies the one-step leapforg integrator for \\ddot{x} = - M \\nabla_x H(x)\n",
    "    r\"\"\"Leap-frog integrator for \\dot{x} = q, \\dot{q} = - M \\nabla_x H(x)\"\"\"\n",
    "    add = torch.Tensor.add_ if inplace else torch.Tensor.add\n",
    "    sub = torch.Tensor.sub_ if inplace else torch.Tensor.sub\n",
    "    if not inplace:\n",
    "        x, q = x.clone(), q.clone()\n",
    "\n",
    "    grad = batch_grad(x, H, q=q)\n",
    "    while True:\n",
    "        # q_{\\tfrac12} = q_0 - \\nabla_x H(x_0) \\tfrac\\epsilon2\n",
    "        q = sub(q, grad * epsilon / 2)\n",
    "\n",
    "        # x_1 = x_0 + M q_{\\tfrac12} \\epsilon\n",
    "        x = add(x, epsilon * (q if M is None else torch.matmul(q, M)))\n",
    "\n",
    "        # q_1 = q_{\\tfrac12} - \\nabla_x H(x_1) \\tfrac\\epsilon2\n",
    "        grad = batch_grad(x, H, q=q)\n",
    "        if clip_grad > 0:\n",
    "            grad = clip_norm(grad, clip_grad, p=2, dim=-1)\n",
    "\n",
    "        q = sub(q, grad * epsilon / 2)\n",
    "\n",
    "        # preemptively flip the sign of the momentum to ease time-reversibility\n",
    "        yield x, -q\n",
    "\n",
    "    # (todo) add stopped process t \\wedge n_j\n",
    "    # (todo) understand what NUTS does and it does\n",
    "    # (todo) investigate rare NANs\n",
    "    # (todo) add time direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Hamiltinian Metropolis Hastings proposal is the same as MH\n",
    "but with varaites in phase-space and \n",
    "\n",
    "$$\n",
    "\\alpha(y\\vert x)\n",
    "    = \\min\\Bigl\\{\n",
    "        1, \\frac{\n",
    "            p(\\theta_y, -q_y)\n",
    "        }{\n",
    "            p(\\theta_x, q_x)\n",
    "        } \\frac{\n",
    "            h_T((\\theta_x, q_x) \\vert (\\theta_y, -q_y))\n",
    "        }{\n",
    "            h_T((\\theta_y, -q_y) \\vert (\\theta_x, q_x))\n",
    "        }\n",
    "    \\Bigr\\}\n",
    "    \\,, $$\n",
    "\n",
    "where $\n",
    "h_T((\\theta, q) \\vert (\\theta_0, q_0))\n",
    "    = \\delta_{\\theta - \\theta_T} \\delta_{q - (-q_T)}\n",
    "$\n",
    "and $(\\theta_T, q_T)$ is the integral of the Hamiltonian ODE at $T$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\dot{\\theta}\n",
    "        =& \\partial_q H(\\theta, q)\n",
    "        \\,, \\\\\n",
    "   \\dot{q}\n",
    "        =& - \\partial_\\theta H(\\theta, q)\n",
    "        \\,,\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "with initial conditions $(\\theta_0, q_0)$. Thus\n",
    "\n",
    "$$\n",
    "\\alpha((\\theta_T, -q_T)\\vert (\\theta_0, q_0))\n",
    "\\alpha_T(\\theta_0, q_0)\n",
    "    = \\min\\Bigl\\{\n",
    "        1, \\frac{\n",
    "            p(\\theta_T, -q_T)\n",
    "        }{\n",
    "            p(\\theta_0, q_0)\n",
    "        } \\frac{\n",
    "            h_T((\\theta_0, q_0) \\vert (\\theta_T, -q_T))\n",
    "        }{\n",
    "            h_T((\\theta_T, -q_T) \\vert (\\theta_0, q_0))\n",
    "        }\n",
    "    \\Bigr\\}\n",
    "%     = \\min\\Bigl\\{\n",
    "%         1, \\frac{\n",
    "%             \\exp{-H(\\theta_T, -q_T)}\n",
    "%         }{\n",
    "%             \\exp{-H(\\theta_0, q_0)}\n",
    "%         }\n",
    "    = \\min\\Bigl\\{\n",
    "        1, \\exp{\\{H(\\theta_0, q_0) - H(\\theta_T, -q_T)\\}}\n",
    "    \\Bigr\\}\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The need for mnegation is to make sure that momentum is flipped and,\n",
    "since hamiltonian dynamics is deterministic and time-reversible, that\n",
    "when integrating back in time from $(\\theta_T, -q_T)$ we recover $(\\theta_0, q_0)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HamiltonianMHProposal(Proposal):\n",
    "    def __init__(self, proposal, target, time=2e-2, delta=1e-3, clip_grad=0):\n",
    "        self.target, self.proposal = target, proposal\n",
    "        self.delta, self.time = delta, time\n",
    "        self.clip_grad = clip_grad\n",
    "    \n",
    "    def log_prob(self, x, q, *, at=None):\n",
    "        return self.target.log_prob(x) + self.proposal.log_prob(q, at=x)\n",
    "\n",
    "    def hamiltonian(self, x, q, *, at=None):\n",
    "        return - self.log_prob(x, q, at=at)\n",
    "\n",
    "    def sample(self, n_samples=1, *, at):\n",
    "        *head, n_features = at.shape\n",
    "        head = [1] if not head else head\n",
    "\n",
    "        assert n_samples == 1\n",
    "        # sample the initial momentum q (from kinetic)\n",
    "        curr = at, self.proposal.sample(n_samples, at=at)\n",
    "\n",
    "        # integrate \\dot{x} = q, \\dot{q} = -\\nabla_x H(x, q)\n",
    "        #  from x_0, q_0 until T flipping the sign\n",
    "        integrator = integrate_(self.hamiltonian, *curr,\n",
    "                                epsilon=self.delta, inplace=False,\n",
    "                                clip_grad=self.clip_grad)\n",
    "        for _, prop in zip(range(-int(-self.time // self.delta)), integrator):\n",
    "            # consume the integrator until the required number of steps is done\n",
    "            pass\n",
    "        del integrator\n",
    "\n",
    "        # \\log q(curr \\vert prop) \\pi(prop) - \\log q(prop \\vert curr) \\pi(curr)\n",
    "        log_alpha = self.log_prob(*prop) - self.log_prob(*curr)\n",
    "        alpha = torch.exp(torch.clamp(log_alpha, max=0))\n",
    "        accept = torch.rand_like(log_alpha) < alpha\n",
    "\n",
    "        self.alpha_, self.log_alpha_ = alpha, log_alpha\n",
    "\n",
    "        return torch.where(accept.unsqueeze(-1), prop[0], curr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's integrate some!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(255, 2)\n",
    "q = torch.randn_like(x)\n",
    "until, epsilon = 0.5, 5e-3\n",
    "\n",
    "int_ = integrate_(hamiltonian, x, q, epsilon=epsilon, inplace=False)\n",
    "path = [(x, q)]\n",
    "path.extend((x, q) for _, (x, q) in zip(tqdm.trange(-int(-until // epsilon)), int_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, q = zip(*path)\n",
    "paths = torch.stack(x, dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll, ur = get_rect(paths.flatten(0, -2))\n",
    "\n",
    "mesh = torch.meshgrid(*map(torch.linspace, ll, ur, [201, 201]))\n",
    "marg = torch.stack(mesh, dim=-1).flatten(0, -2)\n",
    "\n",
    "z = torch.exp(log_density(marg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.contourf(*mesh, z.reshape_as(mesh[0]), levels=51, cmap=plt.cm.terrain)\n",
    "\n",
    "colours = plt.cm.Reds(np.linspace(0.5, 1, num=len(paths)))\n",
    "for i, col in enumerate(colours):\n",
    "    plot_path(paths[i][-100:], color=col, alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  torch.distributions import MultivariateNormal\n",
    "\n",
    "idp = IndependentProposal(MultivariateNormal(torch.zeros(2), torch.eye(2)))\n",
    "hmh = HamiltonianMHProposal(idp, Target(log_density), time=2e-1, delta=1e-2, clip_grad=100)\n",
    "\n",
    "plot_chains(sample_chain(hmh, n_chains=15), log_density)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the sampler\n",
    "from pyhmc import hmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/rmcgibbo/pyhmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logprob(x):\n",
    "    x = torch.from_numpy(x)\n",
    "\n",
    "    logp = log_density(x)\n",
    "    grad = batch_grad(x, log_density)\n",
    "\n",
    "    return logp.numpy(), grad.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhmc import hmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = hmc(logprob, x0=np.random.randn(2), args=(), n_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_chains(torch.from_numpy(samples[np.newaxis]), log_density)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths[0][torch.isfinite(paths[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (~torch.isfinite(paths)).sum(dim=-1).sum(dim=-1)\n",
    "paths[mask > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leap_frog(nabla, q, p, grad=None, eps=0.01):\n",
    "    r\"\"\"Leap-frog integrator for \\dot{p} = - \\nabla_q V(q), \\dot{q} = p\"\"\"\n",
    "    # p_{\\tfrac12} = p_0 - \\tfrac\\epsilon2 \\nabla_q V(q_0)\n",
    "    grad = nabla(q) if grad is None else grad  # .detach()\n",
    "    p.sub_(- eps * grad / 2)\n",
    "\n",
    "    # q_1 = q_0 + \\epsilon p_{\\tfrac12}\n",
    "    q.add_(eps * p)\n",
    "\n",
    "    # p_1 = p_{\\tfrac12} - \\tfrac\\epsilon2 \\nabla_q V(q_1)\n",
    "    grad = nabla(q)\n",
    "    p.sub_(- eps * grad / 2)\n",
    "    return p, q, grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = torch.tensor([\n",
    "    [-3., -3.],\n",
    "    [+3., -3.],\n",
    "    [+3., +3.],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = torch.tensor[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.triangular_solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prob(value, mu, loc):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Normal(mu, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.rsample((10,)).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.log_prob??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = mu[0].clone().requires_grad_(True)\n",
    "target.log_prob(q).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(15, 2)\n",
    "q = torch.randn_like(x)\n",
    "eps = 5e-2\n",
    "\n",
    "# applies the one-step leapforg integrator for \\ddot{x} = \\nabla_x \\ell(x)\n",
    "r\"\"\"Leap-frog integrator for \\dot{x} = q, \\dot{q} = \\nabla_x \\ell(x)\"\"\"\n",
    "\n",
    "paths = [x]\n",
    "grad = batch_grad(x, log_density)\n",
    "for _ in range(2500):\n",
    "    # (todo) add stopped process t \\wedge n_j\n",
    "    # (todo) understand what NUTS does and it does\n",
    "    # (todo) investigate rare NANs\n",
    "\n",
    "    # leap-frog integrator of \\ddot{x} = f(x)\n",
    "    # p_{\\tfrac12} = p_0 + \\nabla_q V(q_0) \\tfrac\\epsilon2\n",
    "    q_half = q + grad * eps / 2\n",
    "\n",
    "    # q_1 = q_0 + p_{\\tfrac12} \\epsilon\n",
    "    x = x + q_half * eps\n",
    "\n",
    "    # p_1 = p_{\\tfrac12} + \\nabla_q V(q_1) \\tfrac\\epsilon2\n",
    "    grad = batch_grad(x, log_density)\n",
    "    q = q_half + grad * eps / 2\n",
    "\n",
    "    paths.append(x)\n",
    "\n",
    "paths = torch.stack(paths, dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "until, epsilon = 1., 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(15, 2)\n",
    "q = torch.randn_like(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrator = integrate_(hamiltonian, x, q, epsilon=epsilon, inplace=True)\n",
    "for _ in zip(range(-int(-until // epsilon)), integrator):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = sample_chain(ldmh, n_chains=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_grad = 10.\n",
    "grad = batch_grad(paths[0], ldmh.target.log_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
